"""
RAG Knowledge Base - Core Implementation
æ ¸å¿ƒå®ç°ï¼šChromaDB + SQLite æ··åˆå­˜å‚¨å’Œæ£€ç´¢
"""
import json
import sqlite3
from datetime import datetime
from typing import List, Dict, Any, Optional
import chromadb
from chromadb.config import Settings
from openai import OpenAI

from rag_config import (
    CHROMA_DB_PATH,
    SQLITE_DB_PATH,
    CHROMA_COLLECTION_NAME,
    OPENAI_EMBEDDING_MODEL,
    OPENAI_API_KEY,
    DISTANCE_METRIC,
    DEFAULT_SEARCH_LIMIT,
    SIMILARITY_THRESHOLD
)

# ==================== åˆå§‹åŒ– ====================

# OpenAI Client
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# ChromaDB Client
chroma_client = chromadb.PersistentClient(
    path=CHROMA_DB_PATH,
    settings=Settings(anonymized_telemetry=False)
)

# ==================== Embedding ç”Ÿæˆ ====================

def generate_embedding(text: str) -> List[float]:
    """
    ä½¿ç”¨ OpenAI ç”Ÿæˆæ–‡æœ¬çš„ embedding
    
    Args:
        text: è¦ç”Ÿæˆ embedding çš„æ–‡æœ¬
        
    Returns:
        Embedding å‘é‡ï¼ˆ1536ç»´ï¼‰
    """
    try:
        response = openai_client.embeddings.create(
            model=OPENAI_EMBEDDING_MODEL,
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"âŒ Error generating embedding: {e}")
        raise

def create_document_text(options_data: dict, ticker: str, date: str) -> str:
    """
    ä»æœŸæƒæ•°æ®åˆ›å»ºç”¨äº embedding çš„æ–‡æœ¬æè¿°
    
    Args:
        options_data: æœŸæƒæ•°æ®å­—å…¸
        ticker: è‚¡ç¥¨ä»£ç 
        date: æ—¥æœŸ
        
    Returns:
        æ–‡æœ¬æè¿°
    """
    results = options_data.get("results", [])
    count = options_data.get("count", 0)
    
    # ç»Ÿè®¡ä¿¡æ¯
    calls = sum(1 for r in results if r.get("contract_type", "").lower() == "call")
    puts = sum(1 for r in results if r.get("contract_type", "").lower() == "put")
    
    # æ‰§è¡Œä»·èŒƒå›´
    strikes = [r.get("strike_price", 0) for r in results if r.get("strike_price")]
    strike_min = min(strikes) if strikes else 0
    strike_max = max(strikes) if strikes else 0
    
    # ç”Ÿæˆæè¿°æ–‡æœ¬
    text = f"""
    Stock Options Data for {ticker}
    Date: {date}
    Total Contracts: {count}
    Call Options: {calls}
    Put Options: {puts}
    Strike Price Range: ${strike_min:.2f} to ${strike_max:.2f}
    Call/Put Ratio: {calls/puts if puts > 0 else 'N/A'}
    Data Source: Polygon.io
    """
    
    return text.strip()

# ==================== ChromaDB æ“ä½œ ====================

def get_or_create_collection():
    """è·å–æˆ–åˆ›å»º ChromaDB collection
    
    é‡è¦ï¼šä¸ä½¿ç”¨ embedding_functionï¼Œå› ä¸ºæˆ‘ä»¬æ‰‹åŠ¨ç”Ÿæˆ embedding
    """
    try:
        collection = chroma_client.get_or_create_collection(
            name=CHROMA_COLLECTION_NAME,
            metadata={
                "hnsw:space": DISTANCE_METRIC
            },
            # ä¸æŒ‡å®š embedding_functionï¼Œæ‰‹åŠ¨æä¾› embeddings
            embedding_function=None
        )
        return collection
    except Exception as e:
        print(f"âŒ Error creating collection: {e}")
        raise

def store_to_chromadb(
    snapshot_id: str,
    text: str,
    embedding: List[float],
    metadata: dict
) -> bool:
    """
    å­˜å‚¨æ•°æ®åˆ° ChromaDB
    
    Args:
        snapshot_id: å¿«ç…§ID
        text: æ–‡æœ¬æè¿°
        embedding: å‘é‡
        metadata: å…ƒæ•°æ®
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        collection = get_or_create_collection()
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"  â†’ Snapshot ID: {snapshot_id}")
        print(f"  â†’ Embedding dimension: {len(embedding)}")
        print(f"  â†’ Document length: {len(text)} chars")
        print(f"  â†’ Metadata keys: {list(metadata.keys())}")
        
        # æ·»åŠ  snapshot_id åˆ° metadataï¼ˆç”¨äºå¼‚åŠ¨æ£€æµ‹ï¼‰
        chroma_metadata = {
            **metadata,
            "snapshot_id": snapshot_id
        }
        
        collection.add(
            ids=[snapshot_id],
            embeddings=[embedding],
            documents=[text],
            metadatas=[chroma_metadata]
        )
        
        print(f"  âœ… Stored to ChromaDB successfully")
        return True
    except Exception as e:
        print(f"âŒ Error storing to ChromaDB: {e}")
        import traceback
        traceback.print_exc()
        return False

def search_chromadb(
    query_text: str = None,
    query_embedding: List[float] = None,
    limit: int = DEFAULT_SEARCH_LIMIT,
    where: dict = None
) -> List[Dict[str, Any]]:
    """
    åœ¨ ChromaDB ä¸­æœç´¢
    
    Args:
        query_text: æŸ¥è¯¢æ–‡æœ¬ï¼ˆä¼šè‡ªåŠ¨ç”Ÿæˆembeddingï¼‰
        query_embedding: ç›´æ¥æä¾› embedding
        limit: è¿”å›æ•°é‡
        where: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
        
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    try:
        collection = get_or_create_collection()
        
        # å¦‚æœæä¾›äº†æ–‡æœ¬ï¼Œç”Ÿæˆembedding
        if query_text and not query_embedding:
            query_embedding = generate_embedding(query_text)
        
        # æœç´¢
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=limit,
            where=where
        )
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        if results and results['ids']:
            for i, snapshot_id in enumerate(results['ids'][0]):
                formatted_results.append({
                    "id": snapshot_id,
                    "distance": results['distances'][0][i],
                    "similarity": 1 - results['distances'][0][i],  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                    "document": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i]
                })
        
        return formatted_results
        
    except Exception as e:
        print(f"âŒ Error searching ChromaDB: {e}")
        return []

# ==================== SQLite æ“ä½œ ====================

def init_sqlite_db():
    """åˆå§‹åŒ– SQLite æ•°æ®åº“"""
    conn = sqlite3.connect(SQLITE_DB_PATH)
    cursor = conn.cursor()
    
    # åˆ›å»ºå¿«ç…§è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS options_snapshots (
        id TEXT PRIMARY KEY,
        ticker TEXT NOT NULL,
        date TEXT NOT NULL,
        timestamp TEXT NOT NULL,
        total_contracts INTEGER,
        calls_count INTEGER,
        puts_count INTEGER,
        strike_min REAL,
        strike_max REAL,
        avg_strike REAL,
        data_json TEXT NOT NULL,
        metadata_json TEXT,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP
    )
    ''')
    
    # åˆ›å»ºç´¢å¼•
    cursor.execute('''
    CREATE INDEX IF NOT EXISTS idx_ticker_date 
    ON options_snapshots(ticker, date)
    ''')
    
    cursor.execute('''
    CREATE INDEX IF NOT EXISTS idx_timestamp 
    ON options_snapshots(timestamp)
    ''')
    
    conn.commit()
    conn.close()
    print("âœ… SQLite database initialized")

def store_to_sqlite(
    snapshot_id: str,
    ticker: str,
    date: str,
    options_data: dict,
    metadata: dict
) -> bool:
    """
    å­˜å‚¨æ•°æ®åˆ° SQLite
    
    Args:
        snapshot_id: å¿«ç…§ID
        ticker: è‚¡ç¥¨ä»£ç 
        date: æ—¥æœŸ
        options_data: æœŸæƒæ•°æ®
        metadata: å…ƒæ•°æ®
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        conn = sqlite3.connect(SQLITE_DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
        INSERT OR REPLACE INTO options_snapshots
        (id, ticker, date, timestamp, total_contracts, calls_count, puts_count,
         strike_min, strike_max, avg_strike, data_json, metadata_json)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            snapshot_id,
            ticker,
            date,
            metadata.get("timestamp"),
            metadata.get("total_contracts"),
            metadata.get("calls_count"),
            metadata.get("puts_count"),
            metadata.get("strike_min"),
            metadata.get("strike_max"),
            metadata.get("avg_strike"),
            json.dumps(options_data),
            json.dumps(metadata)
        ))
        
        conn.commit()
        conn.close()
        return True
        
    except Exception as e:
        print(f"âŒ Error storing to SQLite: {e}")
        return False

def get_from_sqlite(snapshot_id: str) -> Optional[dict]:
    """ä» SQLite è·å–æ•°æ®"""
    try:
        conn = sqlite3.connect(SQLITE_DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT data_json, metadata_json FROM options_snapshots
        WHERE id = ?
        ''', (snapshot_id,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            return {
                "data": json.loads(result[0]),
                "metadata": json.loads(result[1])
            }
        return None
        
    except Exception as e:
        print(f"âŒ Error retrieving from SQLite: {e}")
        return None

def query_sqlite(
    ticker: str = None,
    start_date: str = None,
    end_date: str = None,
    limit: int = 100
) -> List[dict]:
    """
    ä» SQLite æŸ¥è¯¢æ•°æ®
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        limit: é™åˆ¶æ•°é‡
        
    Returns:
        æŸ¥è¯¢ç»“æœåˆ—è¡¨
    """
    try:
        conn = sqlite3.connect(SQLITE_DB_PATH)
        cursor = conn.cursor()
        
        query = "SELECT * FROM options_snapshots WHERE 1=1"
        params = []
        
        if ticker:
            query += " AND ticker = ?"
            params.append(ticker)
        
        if start_date:
            query += " AND date >= ?"
            params.append(start_date)
        
        if end_date:
            query += " AND date <= ?"
            params.append(end_date)
        
        query += " ORDER BY timestamp DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(query, params)
        
        columns = [desc[0] for desc in cursor.description]
        results = []
        
        for row in cursor.fetchall():
            result = dict(zip(columns, row))
            # è§£æ JSON å­—æ®µ
            if result.get('data_json'):
                result['data'] = json.loads(result['data_json'])
            if result.get('metadata_json'):
                result['metadata'] = json.loads(result['metadata_json'])
            results.append(result)
        
        conn.close()
        return results
        
    except Exception as e:
        print(f"âŒ Error querying SQLite: {e}")
        return []


def extract_metadata(options_data: dict, ticker: str, date: str) -> dict:
    """æå–å…ƒæ•°æ®"""
    results = options_data.get("results", [])
    
    calls = [r for r in results if r.get("contract_type", "").lower() == "call"]
    puts = [r for r in results if r.get("contract_type", "").lower() == "put"]
    
    strikes = [r.get("strike_price", 0) for r in results if r.get("strike_price")]
    
    return {
        "ticker": ticker,
        "date": date,
        "timestamp": datetime.now().isoformat(),
        "total_contracts": len(results),
        "calls_count": len(calls),
        "puts_count": len(puts),
        "strike_min": min(strikes) if strikes else 0,
        "strike_max": max(strikes) if strikes else 0,
        "avg_strike": sum(strikes) / len(strikes) if strikes else 0,
        "data_source": "polygon.io"
    }

def detect_options_anomaly(
    ticker: str,
    reference_date: str,
    comparison_dates: Optional[List[str]] = None,
    min_similarity: float = 0.0,
    max_results: int = 10
) -> List[Dict[str, Any]]:
    """
    æ£€æµ‹ options æ•°æ®çš„å¼‚åŠ¨ï¼Œé€šè¿‡å‘é‡ç›¸ä¼¼åº¦å¯¹æ¯”ã€‚
    
    ä½¿ç”¨ ChromaDB çš„å‘é‡ç›¸ä¼¼åº¦æ¥æ‰¾å‡ºä¸å‚è€ƒæ—¥æœŸæœ€ä¸ç›¸ä¼¼çš„æ•°æ®ç‚¹ï¼Œ
    è¿™äº›å¯èƒ½ä»£è¡¨å¸‚åœºçš„å¼‚åŠ¨æˆ–è€…å¼‚å¸¸äº¤æ˜“æ´»åŠ¨ã€‚
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        reference_date: å‚è€ƒæ—¥æœŸï¼ˆåŸºå‡†ï¼‰
        comparison_dates: è¦å¯¹æ¯”çš„æ—¥æœŸåˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸ºNoneåˆ™å¯¹æ¯”æ‰€æœ‰å†å²æ•°æ®ï¼‰
        min_similarity: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œä½äºæ­¤å€¼æ‰è§†ä¸ºå¼‚åŠ¨
        max_results: è¿”å›æœ€å¤šå¤šå°‘ä¸ªå¼‚åŠ¨ç»“æœ
        
    Returns:
        å¼‚åŠ¨åˆ—è¡¨ï¼ŒæŒ‰ç›¸ä¼¼åº¦ä»ä½åˆ°é«˜æ’åºï¼ˆç›¸ä¼¼åº¦è¶Šä½ = å¼‚åŠ¨è¶Šå¤§ï¼‰
    """
    try:
        # è·å– ChromaDB collection
        collection = get_or_create_collection()
        
        # æ­¥éª¤1: è·å–å‚è€ƒæ•°æ®
        conn = sqlite3.connect(SQLITE_DB_PATH)
        cursor = conn.cursor()
        
        # ä» SQLite è·å–å‚è€ƒæ•°æ®
        cursor.execute('''
            SELECT id, ticker, date, total_contracts, calls_count, puts_count,
                   strike_min, strike_max, avg_strike, data_json, timestamp
            FROM options_snapshots
            WHERE ticker = ? AND date = ?
            ORDER BY timestamp DESC
            LIMIT 1
        ''', (ticker.upper(), reference_date))
        
        reference_row = cursor.fetchone()
        
        if not reference_row:
            conn.close()
            return [{
                "error": f"No reference data found for {ticker} on {reference_date}",
                "suggestion": "Try collecting data first using collect_and_store_options"
            }]
        
        reference_id = reference_row[0]
        ref_calls = reference_row[4]
        ref_puts = reference_row[5]
        ref_strike_min = reference_row[6]
        ref_strike_max = reference_row[7]
        ref_avg_strike = reference_row[8]
        ref_total = reference_row[3]
        
        # ä» ChromaDB è·å–å‚è€ƒå‘é‡å’Œæ–‡æ¡£
        reference_result = collection.get(
            ids=[reference_id],
            include=['documents', 'embeddings']  # åŒæ—¶è·å–æ–‡æ¡£å’Œ embedding
        )
        
        if not reference_result or not reference_result['documents']:
            conn.close()
            return [{"error": f"Reference snapshot {reference_id} not found in vector database"}]
        
        reference_doc = reference_result['documents'][0]
        
        # è·å–å­˜å‚¨çš„ embeddingï¼ˆ1536ç»´ï¼‰
        embeddings = reference_result.get('embeddings')
        
        # æ£€æŸ¥ embeddings æ˜¯å¦å­˜åœ¨
        if embeddings is None or len(embeddings) == 0:
            conn.close()
            return [{"error": f"Reference embedding not found for {reference_id}"}]
        
        reference_embedding = embeddings[0]
        
        # æ£€æŸ¥ embedding æ˜¯å¦æœ‰æ•ˆ
        if reference_embedding is None or len(reference_embedding) == 0:
            conn.close()
            return [{"error": f"Reference embedding is empty for {reference_id}"}]
        
        print(f"  â†’ Reference embedding dimension: {len(reference_embedding)}")
        
        # æ­¥éª¤2: æ„å»ºæŸ¥è¯¢æ¡ä»¶
        where_filter = {"ticker": ticker.upper()}
        
        # æ­¥éª¤3: è¿›è¡Œç›¸ä¼¼åº¦æœç´¢
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ query_embeddings è€Œä¸æ˜¯ query_texts
        # è¿™æ ·å°±ä¸ä¼šè§¦å‘ ChromaDB çš„ embedding function
        similar_results = collection.query(
            query_embeddings=[reference_embedding],  # â† ä½¿ç”¨æ‰‹åŠ¨æä¾›çš„ 1536 ç»´ embedding
            n_results=50,
            where=where_filter
        )
        
        # æ­¥éª¤4: å¤„ç†ç»“æœ
        anomalies = []
        
        if similar_results and similar_results['metadatas'] and similar_results['distances']:
            for i, (metadata, distance) in enumerate(zip(
                similar_results['metadatas'][0], 
                similar_results['distances'][0]
            )):
                snapshot_id = metadata.get('snapshot_id')
                
                # è·³è¿‡å‚è€ƒæ•°æ®æœ¬èº«
                if snapshot_id == reference_id:
                    continue
                
                # è·³è¿‡ä¸åœ¨å¯¹æ¯”æ—¥æœŸåˆ—è¡¨ä¸­çš„æ•°æ®ï¼ˆå¦‚æœæŒ‡å®šäº†åˆ—è¡¨ï¼‰
                snapshot_date = metadata.get('date')
                if comparison_dates and snapshot_date not in comparison_dates:
                    continue
                
                # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•° (1 - distance)
                # ChromaDB ä½¿ç”¨ä½™å¼¦è·ç¦»ï¼ŒèŒƒå›´ [0, 2]
                # 0 = å®Œå…¨ç›¸åŒ, 2 = å®Œå…¨ç›¸å
                similarity_score = 1 - (distance / 2)
                
                # åªè¿”å›ç›¸ä¼¼åº¦å¤§äºç­‰äºé˜ˆå€¼çš„
                if similarity_score < min_similarity:
                    continue
                
                # è·å–å®Œæ•´çš„å¿«ç…§æ•°æ®
                cursor.execute('''
                    SELECT id, ticker, date, total_contracts, calls_count, puts_count,
                           strike_min, strike_max, avg_strike, timestamp
                    FROM options_snapshots
                    WHERE id = ?
                ''', (snapshot_id,))
                
                snapshot_row = cursor.fetchone()
                
                if snapshot_row:
                    # è§£ææ•°æ®
                    cmp_total = snapshot_row[3]
                    cmp_calls = snapshot_row[4]
                    cmp_puts = snapshot_row[5]
                    cmp_strike_min = snapshot_row[6]
                    cmp_strike_max = snapshot_row[7]
                    cmp_avg_strike = snapshot_row[8]
                    cmp_timestamp = snapshot_row[9]
                    
                    # è®¡ç®—æ¯”ç‡
                    ref_ratio = ref_calls / ref_puts if ref_puts > 0 else 0
                    cmp_ratio = cmp_calls / cmp_puts if cmp_puts > 0 else 0
                    
                    anomalies.append({
                        "date": snapshot_date,
                        "timestamp": cmp_timestamp,
                        "similarity_score": round(similarity_score, 4),
                        "distance": round(distance, 4),
                        "anomaly_level": "High" if similarity_score < 0.7 else "Medium" if similarity_score < 0.85 else "Low",
                        "metrics": {
                            "total_contracts": cmp_total,
                            "calls_count": cmp_calls,
                            "puts_count": cmp_puts,
                            "call_put_ratio": round(cmp_ratio, 2) if cmp_puts > 0 else None,
                            "strike_range": f"${cmp_strike_min:.2f} - ${cmp_strike_max:.2f}",
                            "avg_strike": f"${cmp_avg_strike:.2f}"
                        },
                        "changes_from_reference": {
                            "total_contracts_change": cmp_total - ref_total,
                            "calls_change": cmp_calls - ref_calls,
                            "puts_change": cmp_puts - ref_puts,
                            "call_put_ratio_change": round(cmp_ratio - ref_ratio, 2),
                            "avg_strike_change": round(cmp_avg_strike - ref_avg_strike, 2)
                        }
                    })
        
        conn.close()
        
        # æŒ‰ç›¸ä¼¼åº¦ä»ä½åˆ°é«˜æ’åºï¼ˆç›¸ä¼¼åº¦è¶Šä½ = å¼‚åŠ¨è¶Šå¤§ï¼‰
        anomalies.sort(key=lambda x: x['similarity_score'])
        
        # è¿”å›å‰ N ä¸ªæœ€å¤§å¼‚åŠ¨
        return anomalies[:max_results]
        
    except Exception as e:
        print(f"Error detecting anomalies: {e}")
        import traceback
        traceback.print_exc()
        return [{"error": f"Anomaly detection failed: {str(e)}"}]

# ==================== åˆå§‹åŒ– ====================

# åœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ–æ•°æ®åº“
init_sqlite_db()

if __name__ == "__main__":
    print("RAG Knowledge Base initialized")
    print(f"ChromaDB path: {CHROMA_DB_PATH}")
    print(f"SQLite path: {SQLITE_DB_PATH}")

