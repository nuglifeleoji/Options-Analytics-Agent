"""
Batch Options Search Tool
Author: Leo Ji

Search for options data for multiple tickers with smart caching.
"""

import json
import time
from langchain_core.tools import tool
from .options_search import search_options


@tool
def batch_search_options(tickers: str, date: str, limit: int = 300) -> str:
    """Smart batch search for multiple tickers with automatic cache fallback.
    
    This tool intelligently searches for options data for multiple tickers:
    1. First checks the knowledge base for each ticker
    2. For tickers found in cache â†’ returns cached data
    3. For tickers NOT found â†’ automatically fetches from API
    4. Optionally stores newly fetched data
    5. Returns combined results
    
    Args:
        tickers: Comma-separated ticker symbols (e.g., 'AAPL,MSFT,TSLA,GOOGL')
        date: Date or month (e.g., '2025-11' or '2025-11-07')
        limit: Contracts per ticker (default: 300)
    
    Returns:
        Summary with cache hits, API fetches, and combined results
    
    Example:
        batch_search_options("AAPL,MSFT,TSLA", "2025-11", 300)
    """
    try:
        # è§£æ tickers
        ticker_list = [t.strip().upper() for t in tickers.split(',')]
        
        print(f"\nğŸ” Batch searching {len(ticker_list)} tickers for {date}...")
        print(f"Tickers: {', '.join(ticker_list)}\n")
        
        results = {
            'cache_hits': [],      # ä»ç¼“å­˜è·å–çš„
            'api_fetches': [],     # éœ€è¦APIè·å–çš„
            'failed': [],          # å¤±è´¥çš„
            'data': {}             # æ‰€æœ‰æ•°æ®
        }
        
        # æ­¥éª¤1: æ£€æŸ¥æ¯ä¸ªtickerçš„ç¼“å­˜
        print("="*70)
        print("ğŸ“¦ STEP 1: Checking cache...")
        print("="*70)
        
        for ticker in ticker_list:
            try:
                from rag.rag_knowledge_base import query_sqlite
                
                cached = query_sqlite(
                    ticker=ticker,
                    start_date=date,
                    end_date=date,
                    limit=1
                )
                
                if cached and cached[0]['total_contracts'] >= limit:
                    # æ‰¾åˆ°ç¼“å­˜
                    print(f"âœ… {ticker:6} - Cache HIT ({cached[0]['total_contracts']} contracts)")
                    results['cache_hits'].append(ticker)
                    
                    # è·å–æ•°æ®
                    cached_data = cached[0]['data']
                    if cached_data.get('count', 0) > limit:
                        cached_data['results'] = cached_data['results'][:limit]
                        cached_data['count'] = limit
                    
                    cached_data['from_cache'] = True
                    cached_data['source'] = 'knowledge_base'
                    results['data'][ticker] = cached_data
                else:
                    # ç¼“å­˜æœªå‘½ä¸­
                    print(f"ğŸ“­ {ticker:6} - Cache MISS (will fetch from API)")
                    results['api_fetches'].append(ticker)
                    
            except Exception as e:
                print(f"âš ï¸  {ticker:6} - Cache check failed: {e}")
                results['api_fetches'].append(ticker)
                
        if results['api_fetches']:
            print(f"\n{'='*70}")
            print(f"ğŸ“¡ STEP 2: Fetching {len(results['api_fetches'])} tickers from API...")
            print("="*70)
            
            for ticker in results['api_fetches']:
                try:
                    print(f"ğŸ”„ Fetching {ticker}...")
                    
                    # è°ƒç”¨ search_optionsï¼ˆä¼šè‡ªåŠ¨å°è¯•ç¼“å­˜ï¼‰
                    data_str = search_options.invoke({
                        "ticker": ticker, 
                        "date": date, 
                        "limit": limit,
                        "force_refresh": True 
                    })
                    
                    data = json.loads(data_str)
                    
                    if "error" in data:
                        print(f"âŒ {ticker:6} - Failed: {data['error']}")
                        results['failed'].append(ticker)
                    elif data.get('count', 0) == 0:
                        print(f"âš ï¸  {ticker:6} - No data found")
                        results['failed'].append(ticker)
                    else:
                        print(f"âœ… {ticker:6} - Fetched {data['count']} contracts")
                        data['from_cache'] = False
                        data['source'] = 'api'
                        results['data'][ticker] = data
                        
                        # å¯é€‰ï¼šè‡ªåŠ¨å­˜å‚¨åˆ°çŸ¥è¯†åº“
                        try:
                            from rag.rag_tools import store_options_data
                            print(f"   ğŸ’¾ Auto-saving to knowledge base...")
                            store_options_data.invoke({
                                "data": data_str,
                                "ticker": ticker,
                                "date": date
                            })
                            print(f"   âœ… Saved!")
                        except Exception as e:
                            print(f"   âš ï¸  Save failed: {e}")
                    
                    # é¿å…APIé™æµ
                    time.sleep(1)
                    
                except Exception as e:
                    print(f"âŒ {ticker:6} - Error: {str(e)}")
                    results['failed'].append(ticker)
        
        # æ­¥éª¤3: ç”Ÿæˆæ‘˜è¦
        print(f"\n{'='*70}")
        print("ğŸ“Š BATCH SEARCH SUMMARY")
        print("="*70)
        
        summary = f"""
ğŸ” Batch Search Complete for {date}

ğŸ“ˆ Results:
  â€¢ Total Tickers: {len(ticker_list)}
  â€¢ From Cache: {len(results['cache_hits'])} âœ…
  â€¢ From API: {len([t for t in results['api_fetches'] if t not in results['failed']])} ğŸ“¡
  â€¢ Failed: {len(results['failed'])} âŒ

"""
        
        if results['cache_hits']:
            summary += f"\nâœ… Cache Hits ({len(results['cache_hits'])}):\n"
            for ticker in results['cache_hits']:
                count = results['data'][ticker].get('count', 0)
                summary += f"  â€¢ {ticker}: {count} contracts\n"
        
        if results['api_fetches'] and len([t for t in results['api_fetches'] if t not in results['failed']]) > 0:
            summary += f"\nğŸ“¡ API Fetches ({len([t for t in results['api_fetches'] if t not in results['failed']])}):\n"
            for ticker in results['api_fetches']:
                if ticker not in results['failed'] and ticker in results['data']:
                    count = results['data'][ticker].get('count', 0)
                    summary += f"  â€¢ {ticker}: {count} contracts (auto-saved to KB)\n"
        
        if results['failed']:
            summary += f"\nâŒ Failed ({len(results['failed'])}):\n"
            for ticker in results['failed']:
                summary += f"  â€¢ {ticker}\n"
        
        # ç»Ÿè®¡æ€»åˆçº¦æ•°
        total_contracts = sum(d.get('count', 0) for d in results['data'].values())
        summary += f"\nğŸ“Š Total Contracts Retrieved: {total_contracts:,}\n"
        
        # æ·»åŠ æ•°æ®å¯ç”¨æ€§ä¿¡æ¯
        summary += f"\nğŸ’¡ All data is now available in the knowledge base for future queries!\n"
        
        return summary
        
    except Exception as e:
        return f"âŒ Error in batch search: {str(e)}"


__all__ = ['batch_search_options']

